{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T9B3B4wnTJC7"
   },
   "source": [
    "## Ejemplo de generacion de audio con WGAN\n",
    "\n",
    "\n",
    "### En este ejemplo se busca utilizar la arquitectura WGAN (Wasserstein GAN) para generar audio. Esta arquitectura de red neuronal es similar a la usada para generar imagenes, pero implementa una función de perdida diferente. Además utilizamos penalización de gradiente al entrenar al modelo discriminador, para evitar que su perdida disminuya a cero.\n",
    "\n",
    "\n",
    "Este tutorial está basado en el trabajo de [HStuart18](https://github.com/HStuart18/tfworldhackathon) que es una implementación de la arquitectura de [WaveGAN](https://github.com/chrisdonahue/wavegan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zJ55_nZVTJC8"
   },
   "source": [
    "Iportante: No se recomienda correr esta red sin una GPU, pues es muy pesada.\n",
    "\n",
    "### Creación del modelo.\n",
    "\n",
    "\n",
    "Primero importamos las librerías necesarias y creamos variables para la GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "cWm0ueRSTJC8",
    "outputId": "c30663b8-4be8-49a7-8400-1c8784bc7a66"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "%load_ext tensorboard\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import time\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from IPython import display\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow.keras.backend as K\n",
    "import librosa.display\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Lambda, Dense, LSTM, Activation, Input, Bidirectional, Dropout, Conv1DTranspose\n",
    "from tensorflow.keras.layers import Reshape, Conv2DTranspose, TimeDistributed, Conv1D, LeakyReLU, Layer, ReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import soundfile as sf\n",
    "# Definimos un uso máximo de memoria de GPU\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth=True \n",
    "session = InteractiveSession(config=config)\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UlIfGJDeTJDG"
   },
   "source": [
    " Esta función crea nuestro modelo discriminador. A diferencia de nuestro ejemplo que utiliza imágenes, este modelo se basa en convoluciones unidimensionales. Esto es porque, en la arquitectura WaveGAN, el audio se recibe como un vector con tantos elementos como puntos muestreados, a diferencia de la arquitectura DCGAN que funciona en base a matrices. \n",
    " \n",
    "Nuestro modelo funcionará en base a intervalos de 1 segundo de audio, con un samplerate de 16384.\n",
    "\n",
    "Usamos phse shuffle en el modelo para aleatorizar la forma que el discriminador percibe las entradas. Esto es necesario pues al generarlas se suelen producir patrones, y no queremos que esto condicione al discriminador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W1awzZ7DTJDG"
   },
   "outputs": [],
   "source": [
    "# def make_discriminator_model():\n",
    "def Critic(d, num_samples, c=1):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Input(shape=(num_samples, 1)))\n",
    "    model.add(Conv1D(c*d, 25, strides=4, padding = 'same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Lambda(lambda x: _apply_phaseshuffle(x)))\n",
    "    # Aplicamos phaseshuffle para aleatorizar las salidas de cada capa, dentro de un margen.\n",
    "    # [4096, 64]\n",
    "    \n",
    "    c *= 2\n",
    "    model.add(Conv1D(c*d, 25 , strides = 4, padding = 'same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Lambda(lambda x: _apply_phaseshuffle(x)))\n",
    "    #[1024, 128]\n",
    "    \n",
    "    c *= 2\n",
    "    model.add(Conv1D(c*d, 25,  strides = 4, padding = 'same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Lambda(lambda x: _apply_phaseshuffle(x)))\n",
    "    #[256, 256]\n",
    "    c *= 2\n",
    "    model.add(Conv1D(c*d, 25,  strides = 4, padding = 'same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Lambda(lambda x: _apply_phaseshuffle(x)))\n",
    "    #[64, 512]\n",
    "    c *= 2\n",
    "    model.add(Conv1D(c*d, 25, strides = 4, padding = 'same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    #[16, 1024]\n",
    "    \n",
    "\n",
    "    model.add(Reshape((16*c*d,)))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "\n",
    "    return model\n",
    "\n",
    "def Generator(d, num_samples, c=16):\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.Input(shape=(100,)))\n",
    "\n",
    "    # output shape = (None, 16, 16d)\n",
    "    model.add(Dense(256*d))\n",
    "    model.add(Reshape((16, 16*d)))\n",
    "    model.add(ReLU())\n",
    "\n",
    "    # Upsampling\n",
    "    # output shape = (None, 64, 8d)\n",
    "    c //= 2\n",
    "    model.add(Conv1DTranspose(c*d,25,strides = 4, padding = 'same'))\n",
    "    model.add(ReLU())\n",
    "\n",
    "    # output shape = (None, 256, 4d)\n",
    "    c //= 2\n",
    "    model.add(Conv1DTranspose(c*d,25,strides = 4, padding = 'same'))\n",
    "    model.add(ReLU())\n",
    "\n",
    "    # output shape = (None, 1024, 2d)\n",
    "    c //= 2\n",
    "    model.add(Conv1DTranspose(c*d,25,strides = 4, padding = 'same'))\n",
    "    model.add(ReLU())\n",
    "\n",
    "    # output shape = (None, 4096, d)\n",
    "    c //= 2\n",
    "    model.add(Conv1DTranspose(c*d,25,strides = 4, padding = 'same'))\n",
    "    model.add(ReLU())\n",
    "\n",
    "    # output shape = (None, 16384, 1)\n",
    "    model.add(Conv1DTranspose(1,25,strides = 4, padding = 'same'))\n",
    "\n",
    "\n",
    "    #### The number of transposed convolution operations  should be modified\n",
    "    #### in accordance with num_samples. This current architecture expects\n",
    "    #### num_samples == 16384\n",
    "\n",
    "    # Squeeze values between (-1, 1)\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "# Makes critic invariant to upsampling artifacts of generator to avoid the critic learning to\n",
    "# easily identify generated audio from said artifacts\n",
    "def _apply_phaseshuffle(x, rad=2, pad_type='reflect'):\n",
    "    b, x_len, nch = x.get_shape().as_list()\n",
    "\n",
    "    phase = tf.random.uniform([], minval=-rad, maxval=rad + 1, dtype=tf.int32)\n",
    "    pad_l = tf.maximum(phase, 0)\n",
    "    pad_r = tf.maximum(-phase, 0)\n",
    "    phase_start = pad_r\n",
    "    x = tf.pad(x, [[0, 0], [pad_l, pad_r], [0, 0]], mode=pad_type)\n",
    "\n",
    "    x = x[:, phase_start:phase_start+x_len]\n",
    "    x.set_shape([b, x_len, nch])\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BeZ_wNorTJDM"
   },
   "source": [
    " Nuestro generador funciona de manera similar al ejemplo de creación de imágenes, pero usando convolusiones unidimensionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tLETF-MxTJDo",
    "outputId": "de4a0134-46ed-430e-9a0f-2a28a71c44b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating necessary directories\n"
     ]
    }
   ],
   "source": [
    "# Hiperparametros y directorios necesarios\n",
    "MODEL_DIMS = 64\n",
    "NUM_SAMPLES = 16384\n",
    "D_UPDATES_PER_G_UPDATE = 5\n",
    "GRADIENT_PENALTY_WEIGHT = 10.0\n",
    "NOISE_LEN = 100\n",
    "EPOCHS = 834 #1600\n",
    "EPOCHS_PER_SAMPLE = 2\n",
    "BATCH_SIZE = 16\n",
    "Fs = 16000\n",
    "\n",
    "DATA_DIR = \"piano/train\"\n",
    "INSTRUMENT = \"piano\"\n",
    "\n",
    "print(\"Creating necessary directories\")\n",
    "\n",
    "paths = [\"logs/traintest3\", \n",
    "         f\"models/{INSTRUMENT}/js\",\n",
    "         f\"output/{INSTRUMENT}\",]\n",
    "\n",
    "for path in paths:\n",
    "    if not os.path.exists(os.path.join(os.getcwd(), path)):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tLETF-MxTJDo",
    "outputId": "de4a0134-46ed-430e-9a0f-2a28a71c44b1"
   },
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self, model_dims=MODEL_DIMS, num_samples=NUM_SAMPLES, \n",
    "                 gradient_penalty_weight=GRADIENT_PENALTY_WEIGHT, instrument=INSTRUMENT,\n",
    "                 noise_len=NOISE_LEN, batch_size=BATCH_SIZE, sr=Fs):\n",
    "        self.model_dims = model_dims\n",
    "        self.num_samples = num_samples\n",
    "        self.noise_dims = (noise_len,)\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.G = Generator(self.model_dims, num_samples)\n",
    "        print(self.G.summary())\n",
    "\n",
    "        self.D = Critic(self.model_dims, num_samples)\n",
    "        print(self.D.summary())\n",
    "        \n",
    "        self.G_optimizer = Adam(learning_rate=1e-4, beta_1=0.5, beta_2=0.9)\n",
    "        self.D_optimizer = Adam(learning_rate=1e-4, beta_1=0.5, beta_2=0.9)\n",
    "        \n",
    "        self.gradient_penalty_weight = gradient_penalty_weight\n",
    "        \n",
    "        self.sr = sr\n",
    "\n",
    "        self.instrument = INSTRUMENT\n",
    "\n",
    "    # Loss function for critic\n",
    "    def _d_loss_fn(self, r_logit, f_logit):\n",
    "        r_loss = - tf.reduce_mean(r_logit)\n",
    "        f_loss = tf.reduce_mean(f_logit)\n",
    "        return r_loss, f_loss\n",
    "    \n",
    "    # Loss function for generator\n",
    "    def _g_loss_fn(self, f_logit):\n",
    "        f_loss = - tf.reduce_mean(f_logit)\n",
    "        return f_loss\n",
    "\n",
    "    # Calculates gradient penalty\n",
    "    def _gradient_penalty(self, real, fake):\n",
    "        def _interpolate(a, b):\n",
    "            shape = [tf.shape(a)[0]] + [1] * (a.shape.ndims - 1)\n",
    "            alpha = tf.random.uniform(shape=shape, minval=0., maxval=1.)\n",
    "            inter = a + alpha * (b - a)\n",
    "            inter.set_shape(a.shape)\n",
    "            return inter\n",
    "        x = _interpolate(real, fake)\n",
    "        with tf.GradientTape() as t:\n",
    "            t.watch(x)\n",
    "            pred = self.D(x, training=True)\n",
    "            \n",
    "        grad = t.gradient(pred, x)\n",
    "        norm = tf.norm(tf.reshape(grad, [tf.shape(grad)[0], -1]), axis=1)\n",
    "        gp = tf.reduce_mean((norm - 1.)**2)\n",
    "\n",
    "        return gp\n",
    "        \n",
    "    # Trains generator by keeping critic constant\n",
    "    @tf.function\n",
    "    def train_G(self, k):\n",
    "        with tf.GradientTape() as t:\n",
    "            z = tf.random.normal(shape=(self.batch_size,) + self.noise_dims)\n",
    "            x_fake = self.G(z, training=True)\n",
    "            x_fake_d_logit = self.D(x_fake, training=True)\n",
    "            topk_predictions = tf.math.top_k(tf.transpose(x_fake_d_logit),k)\n",
    "            G_loss = self._g_loss_fn(tf.transpose(topk_predictions.values))\n",
    "            losstest = self._g_loss_fn(x_fake_d_logit)\n",
    "\n",
    "        G_grad = t.gradient(G_loss, self.G.trainable_variables)\n",
    "        self.G_optimizer.apply_gradients(zip(G_grad, self.G.trainable_variables))\n",
    "\n",
    "        return {'g_loss': G_loss}\n",
    "\n",
    "    # Trains critic by keeping generator constant\n",
    "    @tf.function\n",
    "    def train_D(self, x_real):\n",
    "        with tf.GradientTape() as t:\n",
    "            z = tf.random.normal(shape=(x_real.shape[0],) + self.noise_dims)\n",
    "            x_fake = self.G(z, training=True)\n",
    "\n",
    "            x_real_d_logit = self.D(x_real, training=True)\n",
    "            x_fake_d_logit = self.D(x_fake, training=True)\n",
    "\n",
    "            x_real_d_loss, x_fake_d_loss = self._d_loss_fn(x_real_d_logit, x_fake_d_logit)\n",
    "            gp = self._gradient_penalty(x_real, x_fake)\n",
    "\n",
    "            D_loss = (x_real_d_loss + x_fake_d_loss) + gp * self.gradient_penalty_weight\n",
    "\n",
    "        D_grad = t.gradient(D_loss, self.D.trainable_variables)\n",
    "        self.D_optimizer.apply_gradients(zip(D_grad, self.D.trainable_variables))\n",
    "\n",
    "        return {'d_loss': x_real_d_loss + x_fake_d_loss, 'gp': gp}\n",
    "        \n",
    "    # Creates music samples and saves current generator model\n",
    "    def sample(self, epoch, num_samples=10):\n",
    "        self.G.save(f\"models/{epoch}.h5\")\n",
    "        z = tf.random.normal(shape=(num_samples,) + self.noise_dims)\n",
    "        result = self.G(z, training=False)\n",
    "        for i in range(num_samples):\n",
    "            audio = result[i, :, :]\n",
    "            audio = np.reshape(audio, (self.num_samples,))\n",
    "            sf.write(f\"output/{self.instrument}/{epoch}-{i}.wav\", \n",
    "                                     audio, samplerate=self.sr)\n",
    "        return(z)\n",
    "    def sample_vec(self, vec, num_samples=1):\n",
    "        z = vec\n",
    "        result = self.G(z, training=False)\n",
    "        for i in range(num_samples):\n",
    "            audio = result[i, :, :]\n",
    "            audio = np.reshape(audio, (self.num_samples,))\n",
    "            sf.write(f\"output/{self.instrument}/sample-{i}.wav\", \n",
    "                                     audio, samplerate=self.sr)\n",
    "    \n",
    "    def sample_progres(self):\n",
    "        z = tf.random.normal(shape=(1,) + (NOISE_LEN,))\n",
    "        for model_num in range(0, EPOCHS-1):\n",
    "            if model_num%50 == 0 or model_num == EPOCHS-2:\n",
    "                model = load_model(f'models_1/{model_num}.h5')\n",
    "                self.G = model\n",
    "                result = self.G(z, training=False)\n",
    "                audio = np.reshape(result, (self.num_samples,))\n",
    "                sf.write(f\"output_1/{self.instrument}/sample/{model_num}.wav\", \n",
    "                                         audio, samplerate=self.sr)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tLETF-MxTJDo",
    "outputId": "de4a0134-46ed-430e-9a0f-2a28a71c44b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16384)             1654784   \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 16, 1024)          0         \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 16, 1024)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose (Conv1DTran (None, 64, 512)           13107712  \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 64, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_1 (Conv1DTr (None, 256, 256)          3277056   \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 256, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         819328    \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 1024, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_3 (Conv1DTr (None, 4096, 64)          204864    \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 4096, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_4 (Conv1DTr (None, 16384, 1)          1601      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16384, 1)          0         \n",
      "=================================================================\n",
      "Total params: 19,065,345\n",
      "Trainable params: 19,065,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 4096, 64)          1664      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 4096, 64)          0         \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 4096, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1024, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1024, 128)         0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 1024, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 256, 256)          819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 256, 256)          0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 256, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 64, 512)           3277312   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 64, 512)           0         \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 64, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16, 1024)          13108224  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, 1024)          0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 16385     \n",
      "=================================================================\n",
      "Total params: 17,427,969\n",
      "Trainable params: 17,427,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "gan = GAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tLETF-MxTJDo",
    "outputId": "de4a0134-46ed-430e-9a0f-2a28a71c44b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape = (1175, 16384, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create training data\n",
    "X_train = []\n",
    "for file in os.listdir(DATA_DIR): ### Modify for your data directory\n",
    "    with open(DATA_DIR + \"/\"+f\"{file}\", \"rb\") as f:\n",
    "        samples, _ = librosa.load(f, Fs)\n",
    "        # Pad short audio files to NUM_SAMPLES duration\n",
    "        if len(samples) < NUM_SAMPLES:\n",
    "            audio = np.array([np.array([sample]) for sample in samples])\n",
    "            padding = np.zeros(shape=(NUM_SAMPLES - len(samples), 1), dtype='float32')\n",
    "            X_train.append(np.append(audio, padding, axis=0))\n",
    "        # Create slices of length NUM_SAMPLES from long audio\n",
    "        else:\n",
    "            p = len(samples) // (NUM_SAMPLES)\n",
    "            for i in range(p - 1):\n",
    "                sample = np.expand_dims(samples[i*NUM_SAMPLES:(i+1)*NUM_SAMPLES], axis=1)\n",
    "                X_train.append(sample)\n",
    "\n",
    "print(f\"X_train shape = {(len(X_train),) + X_train[0].shape}\")\n",
    "\n",
    "# Save some random training data slices and create baseline generated data for comparison\n",
    "for i in range(10):\n",
    "    sf.write(f\"output/{INSTRUMENT}/real-{i}.wav\", \n",
    "                             X_train[random.randint(0, len(X_train) - 1)], samplerate=Fs)\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tLETF-MxTJDo",
    "outputId": "de4a0134-46ed-430e-9a0f-2a28a71c44b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: d_loss = -0.017147362232208252 g_loss = 0.0010967960115522146\n",
      "step 5: d_loss = 0.6834036707878113 g_loss = -4.694429397583008\n",
      "step 10: d_loss = -0.18023009598255157 g_loss = 3.6326773166656494\n",
      "step 15: d_loss = -4.363028049468994 g_loss = -1.813288927078247\n",
      "step 20: d_loss = -4.269129753112793 g_loss = -0.6866412162780762\n",
      "step 25: d_loss = -2.3882603645324707 g_loss = 5.47983455657959\n",
      "step 30: d_loss = -1.724114179611206 g_loss = 1.0382493734359741\n",
      "step 35: d_loss = -1.5426703691482544 g_loss = 2.431617498397827\n",
      "step 40: d_loss = -0.7409750819206238 g_loss = -3.147001266479492\n",
      "step 45: d_loss = -1.893587350845337 g_loss = -2.306830644607544\n",
      "step 50: d_loss = -2.0204689502716064 g_loss = 0.6953307390213013\n",
      "step 55: d_loss = -2.312525987625122 g_loss = 2.063833713531494\n",
      "step 60: d_loss = -3.4170126914978027 g_loss = -0.067031130194664\n",
      "step 65: d_loss = -2.40675687789917 g_loss = 0.18770527839660645\n",
      "step 70: d_loss = -2.040931224822998 g_loss = -2.046673536300659\n"
     ]
    }
   ],
   "source": [
    "# Save some random training data slices and create baseline generated data for comparison\n",
    "# for i in range(10):\n",
    "#     sf.write(f\"output/{INSTRUMENT}/real-{i}.wav\", \n",
    "#                              X_train[random.randint(0, len(X_train) - 1)], samplerate=Fs)\n",
    "\n",
    "# gan = GAN()\n",
    "# gan.sample(\"fake\")\n",
    "\n",
    "# train_summary_writer = tf.summary.create_file_writer(\"logs/train\")\n",
    "    \n",
    "# Train GAN\n",
    "gan.sample(\"fake\")\n",
    "nu = 12\n",
    "zeta = 0.99\n",
    "k = BATCH_SIZE\n",
    "train_summary_writer = tf.summary.create_file_writer(\"logs/traintest3\")\n",
    "with train_summary_writer.as_default():\n",
    "    steps_per_epoch = len(X_train) // BATCH_SIZE\n",
    "\n",
    "    for e in range(EPOCHS):\n",
    "        if not e == 0:\n",
    "            k = max(zeta*k, nu)\n",
    "        for i in range(steps_per_epoch):\n",
    "            D_loss_sum = 0\n",
    "        \n",
    "            # Update dcritic a set number of times for each update of the generator\n",
    "            for n in range(D_UPDATES_PER_G_UPDATE):\n",
    "                gan.D.reset_states()\n",
    "                D_loss_dict = gan.train_D(np.array(random.sample(X_train, BATCH_SIZE)))\n",
    "                D_loss_sum += D_loss_dict['d_loss']\n",
    "            \n",
    "            # Calculate average loss of critic for current step\n",
    "            D_loss = D_loss_sum / D_UPDATES_PER_G_UPDATE\n",
    "            \n",
    "            G_loss_dict = gan.train_G(round(k))\n",
    "            G_loss = G_loss_dict['g_loss']\n",
    "        \n",
    "            # Write logs\n",
    "            tf.summary.scalar('d_loss', D_loss, step=(e*steps_per_epoch)+i)\n",
    "            tf.summary.scalar('g_loss', G_loss, step=(e*steps_per_epoch)+i)\n",
    "            if (e*steps_per_epoch)+i % 5 == 0:\n",
    "                print(f\"step {(e*steps_per_epoch)+i}: d_loss = {D_loss} g_loss = {G_loss}\")\n",
    "        \n",
    "        # Periodically sample generator\n",
    "        if e % EPOCHS_PER_SAMPLE == 0:\n",
    "            gan.sample(e)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tLETF-MxTJDo",
    "outputId": "de4a0134-46ed-430e-9a0f-2a28a71c44b1"
   },
   "outputs": [],
   "source": [
    "# noise = tf.random.normal([1, 100])\n",
    "# generated_image = np.array(generator(noise, training=False))\n",
    "# comparison = np.array(X_train[0])\n",
    "\n",
    "\n",
    "# wavfile.write(\"1600epochs.wav\", 16000, *generated_image)\n",
    "\n",
    "# wavfile.write(\"Comparison.wav\", 16384, X_train[0])\n",
    "output, sr = librosa.load(\"output/piano/80-0.wav\", 16384)\n",
    "FIG_SIZE = (15,10)\n",
    "fig = plt.figure(figsize=FIG_SIZE)\n",
    "librosa.display.waveplot(output, 16000)\n",
    "\n",
    "\n",
    "plt.ylabel(\"Amplitud\")\n",
    "fig.savefig('80_piano.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9cf1adc7011a2d1a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9cf1adc7011a2d1a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard --logdir logs/traintest3 --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f297c8c6753541a9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f297c8c6753541a9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard --logdir logs_1/train --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qN8EDNGKTJDu"
   },
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from tensorflow.keras.models import load_model\n",
    "from matplotlib import pyplot\n",
    "from numpy import linspace\n",
    " \n",
    "# load model\n",
    "\n",
    "# generate images\n",
    "def sample(num_samples=5):\n",
    "        model = load_model('models/700.h5')\n",
    "\n",
    "        result = model(z, training=False)\n",
    "        for i in range(num_samples):\n",
    "            audio = result[i, :, :]\n",
    "            audio = np.reshape(audio, (num_samples,))\n",
    "            sf.write(f\"output/sample{i}.wav\", \n",
    "                                     audio, samplerate=self.sr)\n",
    "model = load_model('models/700.h5')\n",
    "gan.G = model\n",
    "# scale from [-1,1] to [0,1]\n",
    "vectores = gan.sample('sample')\n",
    "\n",
    "def interpolate_points(p1, p2, n_steps=10):\n",
    "\t# interpolate ratios between the points\n",
    "\tratios = linspace(0, 1, num=n_steps)\n",
    "\t# linear interpolate vectors\n",
    "\tvectors = list()\n",
    "\tfor ratio in ratios:\n",
    "\t\tv = (1.0 - ratio) * p1 + ratio * p2\n",
    "\t\tvectors.append(v)\n",
    "\treturn asarray(vectors)\n",
    "# plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qN8EDNGKTJDu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "gan.sample_progres()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_points():\n",
    "\t# generate points in the latent space\n",
    "\tx_input = randn(latent_dim * n_samples)\n",
    "\t# reshape into a batch of inputs for the network\n",
    "\tz_input = x_input.reshape(n_samples, latent_dim)\n",
    "\treturn z_input\n",
    "# uniform interpolation between two points in latent space\n",
    "def interpolate_points(p1, p2, n_steps=10):\n",
    "\t# interpolate ratios between the points\n",
    "\tratios = linspace(0, 1, num=n_steps)\n",
    "\t# linear interpolate vectors\n",
    "\tvectors = list()\n",
    "\tfor ratio in ratios:\n",
    "\t\tv = (1.0 - ratio) * p1 + ratio * p2\n",
    "\t\tvectors.append(v)\n",
    "\treturn asarray(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate inception score in numpy\n",
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "from numpy import log\n",
    "from numpy import mean\n",
    "from numpy import exp\n",
    "\n",
    "# calculate the inception score for p(y|x)\n",
    "def calculate_inception_score(p_yx, eps=1E-16):\n",
    "\t# calculate p(y)\n",
    "\tp_y = expand_dims(p_yx.mean(axis=0), 0)\n",
    "\t# kl divergence for each image\n",
    "\tkl_d = p_yx * (log(p_yx + eps) - log(p_y + eps))\n",
    "\t# sum over classes\n",
    "\tsum_kl_d = kl_d.sum(axis=1)\n",
    "\t# average over images\n",
    "\tavg_kl_d = mean(sum_kl_d)\n",
    "\t# undo the logs\n",
    "\tis_score = exp(avg_kl_d)\n",
    "\treturn is_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'imply' from 'numpy' (/home/rafa/.local/lib/python3.8/site-packages/numpy/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-fb98af6ba1da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'imply' from 'numpy' (/home/rafa/.local/lib/python3.8/site-packages/numpy/__init__.py)"
     ]
    }
   ],
   "source": [
    "from numpy import asarray\n",
    "\n",
    "from numpy import expand_dims\n",
    "\n",
    "from numpy import log\n",
    "\n",
    "from numpy import imply\n",
    "\n",
    "from numpy import exp\n",
    "\n",
    " \n",
    "\n",
    "# calculate the inception rating for p(y|x)\n",
    "\n",
    "def calculate_inception_score(p_yx, eps=1e-16):\n",
    "\n",
    "    # calculate p(y)\n",
    "\n",
    "    p_y = expand_dims(p_yx.imply(axis=zero), zero)\n",
    "\n",
    "    # kl divergence for every picture\n",
    "\n",
    "    kl_d = p_yx * (log(p_yx + eps) - log(p_y + eps))\n",
    "\n",
    "    # sum over courses\n",
    "\n",
    "    sum_kl_d = kl_d.sum(axis=1)\n",
    "\n",
    "    # common over pictures\n",
    "\n",
    "    avg_kl_d = imply(sum_kl_d)\n",
    "\n",
    "    # undo the logs\n",
    "\n",
    "    is_score = exp(avg_kl_d)\n",
    "\n",
    "    return is_score\n",
    "\n",
    "\n",
    "p_yx = asarray([0])\n",
    "rating = calculate_inception_score(p_yx)\n",
    "print(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "DCGAN-Copy1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
